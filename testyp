#!/usr/bin/env python3
"""This is a module docstring"""

import sys
import re
import argparse                        # command args
import shlex                           # string split respecting quoting
import shutil                          # which, file copying, etc.
import time                            # for time.monotonic()
import select                          # for poll
from select import POLLIN, POLLOUT, POLLHUP, POLLERR, POLLNVAL

################################################################################
# Module level initialization

# # allow showing embedded newlines in strings
# escape_strs = str.maketrans({"\n" : r"\n"})

# Register translation mechanisms for bad ASCII characters in test
# output. These are passed as the 'errors' argument to Popen() when
# ASCII encoding is in use for output.
codecs.register_error('as_question_marks', lambda e: (u'?',e.start + 1))
codecs.register_error('as_nonascii', lambda e: (u':nonascii:',e.start + 1))

# default valgrind program
valgrind_exit_code = 13
valgrind_prog = [
  "valgrind",
  f"--error-exitcode={valgrind_exit_code}",
  "--leak-check=full",
  "--show-leak-kinds=all",
  "--track-origins=yes",
]

################################################################################
# Basic data types associated with representing tests
class Suite:
  """Encapsulates a collection of tests"""

  def __init__(self):
    """Initialize a default empty Suite"""
    # these fields are set during parsing / initialization, most are options governing behavior
    self.tests = {}                    # tests in the suite in a dictioary with numeric keys starting at 1; first test is "test 1" 
    self.testsnums_torun = []          # contains a list of numbers of tests to run; all tests by default
    self.test_opts = {}                # key/val options affecting tests and sessions set in the preamble
    self.title = None                  # title of the suite from the #+title: directive, None will use the file name
    self.comments = ""                 # comments in the preamble that aren't part of any test
    self.use_points = False            # True if points should be used
    self.points_possible = 0           # total possible points if points are in use, set during parsing
    self.points_scale = 1.0            # Set to a float scaling factor points should be scaled (e.t. 0.5 to halve everything)
    self.show_all = False              # True means print all results on from all tests on the command line; defaults to true for single tests

    # these fields are set during/after the suite evaluation
    self.passed_tests = 0              # total tests passed
    self.points_earned = 0             # total points earned among all tests

class Test:
  """Encapsulates a single test which may have multiple segments"""

  def __init__(self):
    """Initialize a default empty Test"""
    # these fields are set during parsing / initialization
    self.title = None                  # title of the test
    self.linenum = None                # line number on which test starts
    self.points = None                 # number of points assigned, float possible
    self.segments = []                 # list of segments that comprise the
    self.test_directory = None         # directory to use for this test or None if run in the working directory

    # these fields are set during/after the test evaluation
    self.passed = None                 # True for pass, False for fail, None for not run yet

    # these fields are set during formatting
    self.result = None                 # formatted result for test, usually a string but may be anythingthe formatter finds usesful

class Segment:
  """Encapsulate a segment of a test

  Segments run a particular program and check that is output and
  behavior match an expecation. They comprise some preamble / comments
  followed by a session which shows a transcript of what is to be done
  in the test along with its output.
  """

  def __init__(self):
    """Initialize a default empty test Segment"""

    # these fields are obtained from parsing / initializing the segment
    self.title = "Segment"             # title for tests
    self.linenum = None                # line number on which segment starts
    self.comments = ""                 # comments accumulated in the session
    self.commands = []                 # list of shell commands to be run prior to running the session
    self.program = "bash -v"           # program to run for the session, may be #+BEGIN_QUOTE which outputs a file
    self.prompt  = ">>"                # prompt string used by the program being run
    self.echoing = "input"             # style of echoing done by the program, "input" echoes input, "both" for prompt+input echoing
    self.session = ""                  # string with lines of the session of input/output to be used
    self.full_program = None           # full program invocation, may be decorated (usually with valgrind call)
    self.use_valgrind = False          # whether to run program under valgrind
    self.valgrind_reachable = True     # whether to count reachable memory as an error in valgrind
    self.valgrind_prog = valgrind_prog # default valgrind program invocation to use
    self.valgrind_opts = ""            # additional options to pass to valgrind such as suppression
    self.skip_diff = False             # True if diffing the expect/actual should be skipped
    self.skip_return = False           # True if a non-zero exit code should be accepted (e.g. not trigger a failure)
    self.force_ascii_output = True     # translate non-ascii characters in test results to ascii
    self.timeout = 5                   # timeout in (fractional) second to be used before segment is killed
    self.max_out_bytes = 2**20         # maximum size of output from tested program, kill if this is exceeded
    self.post_filter = None            # filter to run on output after test completes, before verifying output
    self.test_result_files = True      # True produces individual test result files
    self.results_prefix = "test"       # file prefix for result output files
    self.results_dir = "test-results"  # base directory for test results files
    self.save_rawfiles = False         # whether to retain any raw input/output files in the raw/ directory
    self.raw_dir = "raw"               # location of raw output files such as Valgrind logs
    self.overall_result_file = False   # True produce an overall result file
    # self.test_title_width = 0          # max width of test titles for aligned printing, calculated during parsing

    # these fields are set after the segment is run
    self.input_str = ""                # string of input extracted from session
    self.output_expect = ""            # expected output extracted from session
    self.output_actual = None          # output program actually produces
    self.output_original = None        # original program output prior to applying post_filter, None if no post filter is used 
    self.output_valgrind = None        # output from Valgrind log file if in use present
    self.sbs_diff = None               # side-by-side diff
    self.lbl_diff = None               # line-by-line diff
    self.diff_failed = None            # True if the diff failed 
    self.retcode = None                # exit/return code of process that was run
    self.messages = []                 # list of string messages indicating failures encountered
    self.timed_out = None              # True if segment timed out during run
    self.maxed_out = None              # True if segment produced more output than max_output_bytes
    self.passed = None                 # True for pass, False for fail, None for not run yet


  def add_prompt_to_output(self):
    """Modify output_actual to include the prompt on appropriate lines"""
    if self.echoing!="input":              # method only works input echoing is enabled
      return                               # inappropriate for "both" echoing
    prompt_lines = []
    input_lines = self.input_str.splitlines()
    inpos = 0
    for outline in self.output_actual.splitlines():
      if inpos < len(input_lines) and outline==input_lines[inpos]:
        outline = prompt + outline
        inpos += 1
      prompt_lines.append(outline)
    self.output_actual = "\n".join(prompt_lines)
    return

  def run_post_filter():                   # TODO
    """Run the post filter to modify otput_actual"""
    return

  def diff_output():                       # TODO
    """Calculate the diff of the output"""
    return


  def set_full_program(self):
    self.full_program = []      # set up the full arg list for the segment

    if self.use_valgrind:
      if not shutil.which("valgrind"):
        self.passed = False
        self.messages.append("Valgrind not found for test that has use_valgrind=1")
        return
      self.full_program.extend(valgrind_prog)  # add base valgrind program and options
      self.full_program.extend(shlex.split(self.valg_opts))
    # end valgrind block

    self.full_program.extend(shlex.split(self.program))  # add on actual program
    

  def set_input_str(self):
    """Creates input_str by extracting prompt lines from session"""
    prompt_len = len(self.prompt)
    input_lines = []
    for line in self.session.splitlines():
      if line.startswith(prompt):
        input_lines.append(line[prompt_len:])
    self.input_str = "\n".join(input_lines)  # input to the be fed to the program

  def set_output_expect(self):
    """Sets the expected output based on the session"""
    self.output_expect = self.session        # unmodified session string is the expected output

  def check_passed(self):                  # TODO
    """Determines if the segment passed according to fields"""
    


  def prerun_setup(self):
    """Completes any internal setup name before running"""
    self.set_full_run_program()
    self.set_input_str()
    self.set_output_expect()
    
  def post_run_setup(self):
    """Finalize fields which can be set after the run finishes"""
    self.add_prompt_to_output()
    self.run_post_filter()
    self.diff_output()
    self.check_passed()


  def run(self):
    """Run an individual segment"""
    # Aiming to avoid any directory creation, file creation, etc.

    self.prerun_setup()                    # set up pending fields for the run
    if self.passed == False:               # already failed in setup
      return

    out_encoding = None
    out_errors = None
    if self.force_ascii_output:            # possibly transform output to ascii
      out_encoding = 'ascii'
      out_errors = 'as_question_marks'
    
    subp = Popen(self.full_program,        # start a subprocess to run the testd program
                 stdin=PIPE, stdout=PIPE,  # communicate with pipes
                 stderr=STDOUT,            # merge stderr with stdout
                 bufsize=0, text=True,     # limit buffering : is this a good idea?
                 encoding=out_encoding,    # optionally transform output
                 errors=out_errors,        # and suppress / catch errors
                 )

    # send input / collect output, limit time/bytes 
    (stdout,timed_out,maxed_out) = \       
      limited_communicate(self.input_str, subp,
                          timeout=self.timeout,
                          max_out_bytes=self.max_out_bytes)

    if timed_out or maxed_out:
      subp.kill()                          # misbehaving, kill it
    subp.wait()                            # should return almost immediately

    self.retcode = subp.returncode
    self.timed_out = timed_out
    self.maxed_out = maxed_out
    self.output_original = stdout
    self.output_actual = stdout
    self.post_run_setup()                  # finalize remaining fields
    return

class SuiteParser:
  """Interface for test file parsers.

  Represents shared functionality of parsers. Implementing classes
  should override parse_file(filename) which will open a given file,
  parse it, and return a Suite
  """

  def parse_file(self,filename):
    """Parse a file (abstract method)

    To be overriden by derived classes. Opens and reads the contents
    of filename and returns a Suite read from it.
    """


  # other shared methods built from parse_file can go here such as
  # parsing_string which can simply convert the given string to a
  # StringIO and then call parse_file


class ParseError(Exception):
  """Exception to throw when a parsing error occurred"""



# def limited_communicate(subp,to_str=None,timeout=None,max_from_bytes=None):
#   """Communicate on a to/from pipe with limits

#   Write to_str to the to_fd in chunks and receive data from from_fd in
#   chunks. If this takes longer than timeout (fractional seconds),
#   bail. If more than from_bytes are read, bail. Returns a tuple of
#     (from_str, timed_out T/F, maxed_out T/F)

#   Makes use of poll() under the hood to synchornously handle the I/O
#   and avoid blocking for too long.
#   """

#   poll_timeout_millis = 100              # timeout for poll calls
#   block_size = 4096                      # size of blocks of data to communicate

#   pollset = select.poll()                # set of file descriptors to track
#   pollset.register(to_fd,   POLLOUT)
#   pollset.register(from_fd, POLLIN)

#   from_blocks = []                       # blocks read from from_fd
#   from_bytes = 0                         # total bytes read from from_fd
#   from_eof = False                       # reached tht end of from_fd
#   total_time = 0.0                       # total time elapsed in the loop
#   to_pos = 0                             # advancing position write in to_str
#   beg_time = time.monotonic()            # start time of main loop
  
#   (loop_count,write_count,read_count) = 0,0,0  # for debugging

#   print(f"working on to_fd {to_fd} from_fd {from_fd}")
#   print(f"POLLOUT {POLLOUT} POLLIN {POLLIN} POLLHUP {POLLHUP} POLLERR {POLLERR} POLLNVAL {POLLNVAL}")

#   while (not from_eof and                         # other from still has data
#          total_time <= timeout and                # still within timeout
#          from_bytes <= max_from_bytes):           # still under max bytes read
#     loop_count += 1
#     fileops = pollset.poll(poll_timeout_millis)
#     print(fileops)

#     # handle 1 event per loop, slightly less efficient than multiple
#     # events but avoids possilbe 
#     for (fd,event) in fileops:                      

#       if (not to_fd.closed and                         # can write to other side
#           fd==to_fd.fileno() and event&POLLOUT and     # and have some left to write
#           to_pos < len(to_str)):                    
#         write_count += 1
#         end_pos = min(len(to_str),to_pos+block_size)
#         to_pos += to_fd.write(to_str[to_pos:end_pos])
#         if to_pos >= len(to_str):                      # IMPORTANT: close outward stream
#           pollset.unregister(to_fd)                    # when all data written so the 
#           to_fd.close()                                # other side knows it's done

#       elif fd==from_fd.fileno() and event&POLLIN:      # can read from inward stream
#         read_count += 1
#         block = from_fd.read(block_size)
#         if len(block)==0:                              # inward stream closed, terminate
#           from_eof = True                              # loop; possibly redundant
#         else:
#           from_blocks.append(block)
#           from_bytes += len(block)

#       elif fd==from_fd.fileno() and event&POLLHUP:     # inward stream closed, terminate
#         from_eof = True                                # loop
#     total_time = time.monotonic() - beg_time
        
#   # print(loop_count,write_count,read_count)             # debugging
#   from_str = "".join(from_blocks)                      # join the read blocks of data
#   return (from_str, (total_time > timeout), (from_bytes > max_from_bytes))

def limited_communicate(subp,to_str=None,timeout=None,max_out_bytes=None):
  """Communicate on a to/from pipe with limits

  Write to_str to the to_fd in chunks and receive data from from_fd in
  chunks. If this takes longer than timeout (fractional seconds),
  bail. If more than from_bytes are read, bail. Returns a tuple of
    (from_str, timed_out T/F, maxed_out T/F)

  Makes use of poll() under the hood to synchornously handle the I/O
  and avoid blocking for too long.
  """

  to_fd = subp.stdin
  from_fd = subp.stdout

  poll_timeout_millis = 100              # timeout for poll calls
  block_size = 4096                      # size of blocks of data to communicate

  pollset = select.poll()                # set of file descriptors to track
  pollset.register(to_fd,   POLLOUT)
  pollset.register(from_fd, POLLIN)

  from_blocks = []                       # blocks read from from_fd
  from_bytes = 0                         # total bytes read from from_fd
  from_eof = False                       # reached tht end of from_fd
  total_time = 0.0                       # total time elapsed in the loop
  to_pos = 0                             # advancing position write in to_str
  beg_time = time.monotonic()            # start time of main loop
  
  (loop_count,write_count,read_count) = 0,0,0  # for debugging

  # print(f"working on to_fd {to_fd} from_fd {from_fd}")
  # print(f"POLLOUT {POLLOUT} POLLIN {POLLIN} POLLHUP {POLLHUP} POLLERR {POLLERR} POLLNVAL {POLLNVAL}")

  while (not from_eof and                                       # other from still has data
         (not timeout or total_time <= timeout) and             # still within timeout
         (not max_out_bytes or from_bytes <= max_out_bytes)): # still under max bytes read
    loop_count += 1
    fileops = pollset.poll(poll_timeout_millis)
    # print(fileops)

    # handle 1 event per loop, slightly less efficient than multiple
    # events but avoids possilbe 
    for (fd,event) in fileops:                      

      if (not to_fd.closed and                         # can write to other side
          fd==to_fd.fileno() and event&POLLOUT and     # and have some left to write
          to_pos < len(to_str)):                    
        write_count += 1
        end_pos = min(len(to_str),to_pos+block_size)
        to_pos += to_fd.write(to_str[to_pos:end_pos])
        if to_pos >= len(to_str):                      # IMPORTANT: close outward stream
          pollset.unregister(to_fd)                    # when all data written so the 
          to_fd.close()                                # other side knows it's done

      elif fd==from_fd.fileno() and event&POLLIN:      # can read from inward stream
        read_count += 1
        block = from_fd.read(block_size)
        if len(block)==0:                              # inward stream closed, terminate
          from_eof = True                              # loop; possibly redundant
        else:
          from_blocks.append(block)
          from_bytes += len(block)

      elif fd==from_fd.fileno() and event&POLLHUP:     # inward stream closed, terminate
        from_eof = True                                # loop
    total_time = time.monotonic() - beg_time
        
  # print(loop_count,write_count,read_count)             # debugging
  from_str = "".join(from_blocks)                      # join the read blocks of data
  timed_out = False
  return (from_str,
          timeout!=None and total_time > timeout,
          max_out_bytes!=None and from_bytes > max_out_bytes)



def get_keyval(string):

  """For 'key=val', returns (key,val)

  Accept a string of the form 'key=val' and separate the key/value
  pair. Raises an exception if there is a formatting problem.
  """
  if "=" not in string:
    raise ParseError(f"key=value string [{string}] is not formatted correctly")
  (key,val)=string.split("=",1)
  if val[0] in """\"\'""":      # check for leading quotes in val
    if val[-1] != val[0]:       # ensure the quoting is complete, error otherwise
      raise ParseError(f"key=value string [{string}] has an unterminated quote")
    val = val[1:-1]             # quoted properly so peel quotes off of value
  return (key,val)

def propogate_fields(obj, options):
  """If any field of obj has a key in options, set that field to the
  associated value in options

  """
  for key,val in options:
    if key in obj.__dict__:
      obj.__dict__[key] = val


# # Example of how to extract an excetion message
# try:
#   get_keyval("""program='./test_el_malloc "Single Allocation\"""")
# except Exception as e:
#   str(e)

class FilePos:
  """Encodes a file position for error reporting"""
  def __init__(self, fname):
    self.filename = fname
    self.linenum = 0

def slurp(filename):
  """Read an entire file into memory"""
  with open(filename,encoding='utf-8') as f:
    return str(f.read())

def shave_blanks(line_list):
  """Elimnate whitespace-only strings from beginning/end of list"""
  beg = 0
  for line in line_list:
    if not re.fullmatch(r"\s*",line):
      break
    beg += 1

  end = len(line_list)
  for line in reversed(line_list):
    if not re.fullmatch(r"\s*",line):
      break
    end -= 1
  return line_list[beg:end]


class OrgSuiteParser:
  """Handle Emacs Org formatted files"""

  def parse_file(self,filename):
    """Parse an Emacs Org formatted files

    Org files are the traditional format to create readable, compact
    test files. This function parses an Org file and builds a Suite
    from it.
    """

    contents = slurp(filename)

    preamble_endpos = contents.find("\n* ")              # locate preamble end/test start
    if preamble_endpos==-1:                              # check if any tests exist
      msg = f"{filename} does not contain any tests"
      raise ParseError(msg)
    preamble = contents[:preamble_endpos+1]              # include the newline


    test_regex = re.compile(r"(^\* .*\n)",re.MULTILINE)  # split remaining content
    tc_list = re.split(test_regex,                       # into tests based on test headers;
                       contents[preamble_endpos+1:])     # then zip the header and test
    tc_len = len(tc_list)                                # content together for later
    test_titles_contents = zip(tc_list[1:tc_len:2],      # iteration
                               tc_list[2:tc_len:2])

    filepos = FilePos(filename)                          # track global file position
    try:                                                 # try block for parsing errors
      suite = self.parse_suite_preamble(preamble,filepos)
      test_index = 1
      for test_title,test_content in test_titles_contents:
        test = self.parse_test(test_title, test_content,
                               suite.test_opts, filepos)
        suite.tests[test_index] = test
        test_index++

    except ParseError as e:
      msg = f"{filepos.filename}:{filepos.linenum}: {str(e)}"
      raise ParseError(msg) from e                       # decorate parsing errors position

    return suite


  def parse_suite_preamble(self, preamble, filepos):
    """Preamble parsing preceding the first test"""
    suite = Suite()
    preamble_comments = []                 # comment lines accumulated in the preamble
    for line in preamble.splitlines():
      filepos.linenum += 1                 # track line number for error reporting
      (first,rest) = ("",line)
      if " " in line:
        (first, rest) = line.split(" ",1)  # extract the first token on the line
        first = first.upper()              # upper case for case insensitive matching

      if first == "#+TITLE:":              # title as in [#+TITLE: Tests for blather]
        suite.title = rest

      elif first == "#+TESTY:":            # option directive like [#+TESTY: program='bc -iq']
        (key,val) = get_keyval(rest)       # raises an exception if badly formatted
        if key in suite.__dict__:
          suite.__dict__[key] = val        # python objects are dicts, exploit this to assign the value
        else:
          suite.test_opts[key] = val
      else:
        preamble_comments.append(line)     # not a directive or key val, append to comments

    preamble_comments = shave_blanks(preamble_comments)

    suite.comments = "\n".join(preamble_comments)
    return suite


  def parse_test(self,test_title,content,opts,filepos):
    """Parse a single test"""
    test = Test()
    test.title = test_title[2:-1]                            # remove "* " and newline
    filepos.linenum += 1
    test.linenum = filepos.linenum
    
    propogate_fields(test,opts)

    # TODO Handle :PROPERTIES: drawer here

    seg_regex = re.compile(r"^#\+(?:END_SRC|END_QUOTE).*\n", # split on ending tokens for
                           re.MULTILINE | re.IGNORECASE)     # segments; note that a line
    seg_contents = re.split(seg_regex, content)              # is excised from resulting list

    for segc in seg_contents:
      if re.fullmatch(r"\s*",segc):                          # completely blank region 
        filepos.linenum += segc.count("\n")                  # add line count and 
        continue                                             # advance
      segment = self.parse_segment(segc,opts,filepos)
      test.segments.append(segment)
      filepos.linenum += 1                                   # add excised line

    return test

  def parse_segment(self,content,opts,filepos):
    """Parse a single segment"""
    segment = Segment()
    propogate_fields(segment,opts)
    segment.linenum = filepos.linenum+1               # first line o fsegment is next

    seg_regexs = r"(^#\+(?:BEGIN_SRC|BEGIN_QUOTE).*\n)"            # split content into premable/session;
    seg_regex = re.compile(seg_regexs, re.MULTILINE|re.IGNORECASE) # retain the SRC/QUOTE as it is
    (preamble,token1,session) = re.split(seg_regex, content)       # used to alter the session program

    comment_lines = []                                # handle the preamble, comments and
    for line in preamble.splitlines():                # prior to the first test
      filepos.linenum += 1
      (first,rest) = ("",line)
      if " " in line:
        (first, rest) = line.split(" ",1)             # extract the first token on the line
        first = first.upper()                         # upper case for case insensitive matching
      if first=="#+TESTY:" and rest[0]=="!":          # shell command as in [#+TESTY: !rm file.txt]
        segment.commands.append(rest[1:])             # peel off the ! at the start
      elif first == "#+TESTY:":
        (key,val) = get_keyval(rest)                  # raises exception if badly formatted
        segment.__dict__[key] = val
      else:
        comment_lines.append(line)

    comment_lines = shave_blanks(comment_lines)       # eliminate blanks and join comments
    segment.comments = "\n".join(comment_lines)       # to comprise the segemnt comments

    filepos.linenum += 1                              # accounts for beginning token
    if not token1.upper().startswith("#+BEGIN_SRC"):  # not a program-based session
      segment.program = token1                        # overwrite program

    segment.session = session
    filepos.linenum += session.count("\n")            # update based on #lines in session

    return segment

def do_test_suite():
  suite = OrgSuiteParser().parse_file("examples/parse_example.org")
  
  for test in suite.tests:
    print(f"TITLE: {test.title} <{test.linenum}>")
    i = 0
    for seg in test.segments:
      print(f"{i} <{seg.linenum}>:\n{seg.comments}\nPROGRAM: {seg.program}\n{seg.session}")
      i += 1

short_description = """\
Run tests for a shell program specified in an org-like file and report
the results.
"""

long_description = """\
----------------------------------------
--- RUNNING TESTS ---
----------------------------------------
Running a test is done from the command line and will default to
running all tests in a provided test file. Output shows each test with
a pass/fail and failures have results files indicating what went
wrong. Below is an example from the examples/ directory:
"""

parser_types = {
  "org" : OrgSuiteParser()
}

def main():
  # set up arg parsing, don't line-wrap descriptions
  argparser = argparse.ArgumentParser(description=short_description,
                                      epilog=long_description,
                                      formatter_class=argparse.RawDescriptionHelpFormatter)
  argparser.add_argument("-t","--input_type",default="org",action="store",
                         choices=["org","json"],
                         help="Specify the test input file type")
  argparser.add_argument("testfile",metavar="testfile",
                         help="File containing tests (default org format)")
  argparser.add_argument("testnums",metavar="testnum",nargs='*',type=int,
                         help="Optional test numbers to run (default all)")

  args = argparser.parse_args()
  print(f"testfile: {args.testfile}")
  print(f"testnums: {args.testnums}")

  if args.input_type not in parser_types:
    print(f"ERROR: test suite file type {args.input_type} is not supported")
    sys.exit(1)
  suite_parser = parser_types[args.input_type]

  try:
    suite = suite_parser.parse_file(args.testfile)
  except ParseError as e:
    print(str(e))
    sys.exit(1)

  print(f"parsing succeeded, suite has {len(suite.tests)} tests")

  suite.testnums_torun = args.testnums or list(range(1,len(suite.tests)+1))





################################################################################
# Main Entry point
if __name__ == '__main__':
  main()  
