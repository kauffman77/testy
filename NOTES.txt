# -*- mode: Org;-*-

* TODO Python Port
- [ ] Finalize docs of current Bash version and commit
- [ ] Enumerate different Python process abstractions and pick one
  line of attack. Some preliminary work in file:pesty-testing
- [ ] Revisit the architecture interplay between testy-single and
  testy-multi: the single case is quite complex due to sharing
  infrastructure with multi in the Bash version and I'd like something
  a little simpler
- [ ] Outline priority features of the port
  1. Single testing
  2. Points
  3. testy-regen support for multi-part tests; would make regeneration a
     lot easier; possibly build in regeneration into the utility itself
  4. Multi-testing
  5. Eliminate some decorator utilities which are dependencies
     - stdbuf : can python adjust its stdbuf before execing? They might
       actually have a different internal model for this
     - timeout: if Python can handle this internally, that'd be better
       than the current need to start up another process
  6. Signal support within tests
  Keep an eye out for utilizing multiple processes at some point down
  the line and try to make design decisions that don't make this
  harder

* TODO General Improvements
- Refactor Mac install script to remove massive redundancy in code
- TESTY_MULTI commands don't work unless there is a exactly one space
  separating the tokens. This defies common convention/expectation.
  Work out a function to split words on spaces and use it in the MULTI
  functionality to make this more robust.
- Re-arrange the example files into directories
  - Currently all under file:examples/ but could organize these a bit
    more with its own README
- Remove the need to pass 'cat' as the filter to various
  TESTY_MULTI commands
- Test number boundary checking : none present so specifying an
  out-of-bounds test fails with uninformative message (e.g. 4 tests
  present, run #5)
- Add multi-part test handling to ~testy-regen~
- Truncate output to some configurable amount; for infinite loops that
  produce lots of output this will lead to better outcomes
- Explore use of HERE docs to simplify some of the output format
  creation. 
- Add documentation for TESTY_MULTI
- Add a manual page and texinfo file
  - Have a git branch for the man page set up and am experimenting
    with formatting but org output formatting for man pages is a bit
    broken 

* TODO Design Ideas for Multiple Processes
- May want to start multiple processes each running its own test
- Improve efficiency a la ~make -j~
- Makes sense for some codes though though must make sure tests are
  independent - could improve this by making directories for each
  running test

** Design based on Child Processes
- Must start child processes from parent testy
- Could have a special mode in which testy is invoked with a --child
  argument which puts it in child mode
- All the child process does is pick up the test file, run the given
  test funneling output into the expect / actual files
- Testy itself can ~wait~ for a finishing jobs and note the
  correspondence of child PID to test numbers
- Track completed tests in an array and print out results of ok / FAIL
  up to the highest completed ID; if tests finish out of order will
  stall at a lower number but this will preserve the ordering of
  output
- On completing a test with the child exiting, testy can check if
  there is another test to run and launch another child on a test
- An initial loop to start a number of child processes equal to the
  specified number of jobs will cause the above loop to keep that
  number of children live
- Need some code that would pares the results file to determine
  overall results; essentially all that is needed is to determine if
  the test passes or fails calculation of overall results, making sure
  the first line of results files indicate failure should make this
  relatively easy
- Even in serial mode code use this device
  - spawn a child process via --child each test to run it
  - wait on results before launching another one
  - would pave the way for multi-process execution and ensure
    consistency between single and multip-process execution
  - would make debugging harder so delay this implementation
- Pseudocode 
#+BEGIN_SRC text
assoc array childpid_to_testnum[]
      array testnum_status[]

for nexttest=1 to min(maxchild, length(tests))
  childpid = testy --child testfile.org i
  childpid_to_testnum[childpid] = nexttest
done
nexttest = 1 + min(maxchild, length(tests))


for i=1 to length(tests)
  testnum_status[i] = "running"
done

curtest = 1

for i=1 to length(tests)  
  wait -n -p childpid
  testid = childpid_to_testnum[childpid]
  testnum_status[testid] = "ok/fail"

  if nexttest <= length(tests)
    childpid = testy --child testfile.org nexttest
    childpid_to_testnum[childpid] = nexttest
    nexttest++
  fi

  while testnum_status[curtest] != "running"
    print "Test $curtest : $testnum_status[$curtest]\n"
    curtest++
  done
done
#+END_SRC
- This design involves no fancy coordination, will only stall printing
  on a very long early test, should be reasonably robust
- Requires certain state to be transmitted between child proc and
  parent testy, namely test result, but may be able to do this in a
  file, pipe, through captured output, or something like that
- Avoids any need for fancy terminal manipulations which will
  mean it works fine in emacs shells / compiles as well

* TODO Bad File Descriptors
When programs in a TESTY_MULTI session segfault, sometimes get bad
file descriptors during reads in testy itself which leads to errors
printing. Not sure how this could be happening so will need to do some
sleuthing.

#+BEGIN_SRC sh
val (master) [solution-p2-4061]% pwd
/home/kauffman/4061-S2021/projects/p2-blather/solution-p2-4061

val (master) [solution-p2-4061]% make test
./testy test_blather.org
============================================================
== test_blather.org : Blather Application Tests
== Running 20 / 20 tests
1)  Server Start/End                : FAIL -> results in file 'test-results/blather-01-result.tmp'
2)  Single Client Join / Depart     : FAIL -> results in file 'test-results/blather-02-result.tmp'
3)  Single Client Join + Shutdown   : FAIL -> results in file 'test-results/blather-03-result.tmp'
./testy: line 713: read: read error: 0: Bad file descriptor
4)  Single Client Messages          : FAIL -> results in file 'test-results/blather-04-result.tmp'
..
#+END_SRC

* DONE Pseudo-Terminals and Testy                                     :testy:
Investigating use of pseudo-terminals for better control of program
input/output, "tricking" programs into thinking they are being used
interactively

Unfortunately there is no way to create pty's from within bash, moving
this to "pesty" python implementation

Jack used them in his 'testius' implementation, python provides
support for this in a pty module.

Jack's testius also uses a variety of other interesting commands
involving pseudoterminals which are worth learning about.

There appears to be no way to create pseudoterminals in bash directly
so if I went this route, I'd likely need to port to Python.

Experimentation with pseudo-terminals also revealed the following
which is something Jack observed that I'd forgotten he said:
- Writing to a pty feeds to a process and displays on the screen
- However, writing in that way goes into the same buffer that the
  program would read
- A parent which writes to a pty then reads is in a race with the
  child and often just reads back exactly what was written and the
  child never gets a chance to see it
To that end *pipes* are better even if they necessitate echoing
explicitly by the program


* Completed Items
** DONE Completed General Improvements
- Add message on how to run test with interactive input in GDB, now
  possible as input for single tests is in a file
- Fix valgrind naming bug introduced after merge of single/multi test
  functionality : needed to copy program-specific valgrind file to
  single valgrind file output for single sessions. Also stemmed from
  misnamed global variable ~program_valg_file~ instead of
  ~program_valgfile~.
- Refactor internals to merge several nearly-identical functions for
  TESTY_MULTI and single program tests; this will ease maintenance
- Added a message about how to run a single test in GDB but only
  relevant to non-interactive tests;
  - Done but could also add a way to run it with input from input
    files at least for single tests
- Adjust standard single tests to add failures to lists like they
  do in TESTY_MULT
- Add signal handling to do cleanup if needed
- If a file doesn't end in a newline, this can cause the last line
  of a testing session to be missed. Try to make this a bit more
  robust. Use the DEBUG output to see when the last line of the
  session is missed
  - Pretty sure this was fixed in a commit at or before 4/11/2021
- Consider the styles of failure listing in MULTI versus show
  everything in SINGLE. Not sure which is preferred but it seems odd
  to have two different formats. Further merger is possible.
  - Did this during merger of single/multi functionality
- Remove use of 'mkfifo', perhaps FIFOs altogether as this feature
  does not work on Windows file systems under the WSL
  - Bash doesn't have a way to create a plain pipe nor a pty so
    this is better reserved for the pesty python version
- Added Immediate files via the BEGIN_QUOTE tag to quickly and easily
  generate test input files that are baked into the test themselves
- Added ~testy-regen~ which is a simple script to regenerate all test
  results using the current "actual" results as the new "expect"
  results; fails for multi-part tests but otherwise a time-saver
- Catch syntax errors in testy sources for ~eval~ expressions in
  blocks and report a syntax error on the associated line in the test
  file; previously this just led to garbage errors being printed
- Catch signals and clean up files if interrupt/term signal is given
- Add support for Valgrind: re-run previous test to check for valgrind
  results
- Added support for testing multiple programs at once via TESTY_MULTI
  which can launch multiple coordinate programs and check their
  behavior
- Add automatic regeneration of test results
  - LOW PRIORITY: the actual results for test are stored in files
    which can easily be re-inserted into the Org SRC blocks via
    commands in emacs.
- Re-checked example files in file:examples/ to guarantee that all of
  them work as expected


** DONE Use of Bash Co-Processes
Investigated these briefly after seeing a reference to them. They are
useless wrt to testy as they have the following idiotic nature:
#+BEGIN_QUOTE
I wouldn't touch coproc. When the co-process exits, the variables
through which you accessed it (like its stdout file descriptor) are
unset, and that sometimes happens before you had a chance to even
start consuming the output, or capture the PID. (Try consuming the
output of ls, and then do it again with sleep before you
consume. Ops...) So maybe your script works most of the time, but when
timings are less lucky, it randomly fails. Named pipes, on the other
hand, will not be suddenly gone. It's more fiddling, but at least it's
deterministic. â€“

-- ddekany May 24, 2021 at 19:16 
https://superuser.com/questions/184307/bash-create-anonymous-fifo
#+END_QUOTE

An example use is here which demonstrates the async problem indicated
in the comment
#+BEGIN_SRC sh
#!/bin/bash

printf "About to launch a coproc\n"

coproc MYLS { ls -l; }

printf "proc id %s\n" "$MYLS_PID"
printf "Pipe fds: %s %s\n" "${MYLS[0]}" "${MYLS[1]}"

printf "Output from child:\n"
while IFS= read -u "${MYLS[0]}" -r line; do
    printf "%s\n" "$line"
done
# In all tested cases this loop errors out prior to completion as the
# child process finishes and this eliminates the pipes connecting it
# ot the parent.  This is a missed opportunity

printf "Waiting on child\n"
wait $MYLS_PID

printf "Done\n"
#+END_SRC

** DONE Add Output for Correct/Passing Tests
- Output results files even for passing tests - makes understanding
  output easier at the minor expense of more disk space
- Perhaps show diff with matching: done
- In output files at top (title), show PASS or FAIL

Student commented that it would be nice if passing tests had their
output files in a separate directory to make it easier to find failing
test results

** DONE Merging Single / TESTY_MULTY functionality
- TESTY_MULTI is more general
- For a single test, just need to start the child process, feed it
  input, then check the results
- Select a single key for the main program like "MAIN"
- Using testy_multi would allow signals, EOF to be passed to the
  program

#+BEGIN_SRC text
>> START bruce ./banter_client bruce
program_start key cmd  -- does cmd need valgrind etc?

>> INPUT bruce Aaaaal-freeeeed!
program_start key input  -- used in session loop to send input

>> WAIT bruce
program_wait key  -- used at end

${program_input__fifo[$key]}  
input to program via FIFO

${program_output_file[$key]}  
output for program

${program_valgfile[$key]}  
valgrind output


#+END_SRC

*** run_test_multi_session
- There are a bunch of arrays that are set up at the beginning of this
  function that would also be required for a single session to be
  compatible, will want to spin this into its own setup function so it
  can be used for either single or multi sessions
- There is a diff_expect_actual command as well which checks the
  output produced by the multi session; could re-use this for the
  output of the program in the single mode
- Big difference in post processing is the need to loop over multiple
  programs
- Multi always produces a results file which we want anyway


|                    | SINGLE               | MULTI                  |                                                        |
|--------------------+----------------------+------------------------+--------------------------------------------------------|
| Initialization     | session_setup        | ""                     | Like first part of current run_test_multi_session      |
| Session Input Loop | session_single_input | session_multi_input    | likely cleaner to split these but possible overlap     |
| Wrap-up            | inline, single wait  | inline, multiple waits | don't need a function for this as its relatively short |
| diff checks        | diff_expect_actual   | ""                     | Both have output files, should be able to re-use       |
| retcode checks     | check_return         | looped check_return    | Single function to check for failures via return code  |
|                    |                      |                        |                                                        |

*** Name Collisions
- program_status[] :: running, killed, finished etc. assoc array of all
  programs that are part of the test
- status :: of the test, ok / FAIL, likely rename to ~test_status~
- PASS_STATUS :: is ok, constant string for passing test
- FAIL_STATUS :: is FAIL, constant string for failing test

*** Use of read() command + Expected Output 
- Currently being handled via sed on the test file, not great, could
  accumulate these in arrays instead
- Could also accumulate session commands in an array and iterate over
  them, passing them as args or as a global variable; this would
  likely beat the ~read~ approach with its weirdness


*** Handling of input / output / valgrind
- In multi-sessions, each program has its own input/output/valgrind
  files
- Overkill for single session where want shorter names for raw
  input for single program 
- Still want to share the functionality as much as possible
- These are not hard to adjust though, files / fifos / etc associated
  with a program key but don't need to name them according to the same
  convention in both single / multi
  #+BEGIN_SRC sh
  # SINGLE MODE
  program_output_file["theprog"]="test-results/raw/${prefix}-05-actual.tmp"
  # ACTUAL is the same as as single program output

  # MULTI MODE
  program_output_file[$key]="test-results/raw/${prefix}-05_${key}_output_file.tmp"
  # ACTUAL file is distinct as it is output produced by the testy multi handler
  #+END_SRC
- Actually can't do the above because ~program_start()~ has its own
  convention for naming; could symlink or hardlink actual_file after
  the fact - e.g. 
  #+BEGIN_SRC sh
  ln "${program_output_file["theprog"]}" "$actual_file"
  if [[ use_valgrind ]]; then
      ln "${program_valgfile["theprog"]}" "valgrind_file"
  fi
  #+END_SRC
- Note the modest conflict/overlap between single test outputs and
  multi test outputs and the ACTUAL file
- May be able to extract expected input and simply cat the file into
  the input pipe for the program so no need to do things differently
  between single and multi

** DONE Avoiding Subshell Error messages During TESTY_MULTI
During TESTY_MULTI if a child processes segfault bash will report
the error and it is devilishly hard to subdue this reporting. It
looks like
#+BEGIN_SRC sh
> ./testy test_blather.org 1
============================================================
== testy test_blather.org
== Running 1 / 20 tests
./testy: line 224: 1372111 Segmentation fault      ( { for tofd in "${program_input__fifo_fd[@]}";
do
    if [[ "$tofd" != "CLOSED" ]]; then
        exec {tofd}>&-;
    fi;
done; eval exec $cmd; } )
1)  Server Start/End                : FAIL -> results in file 'test-results/blather-01-result.tmp'
============================================================
RESULTS: 0 / 1 tests passed
...
#+END_SRC

- Exploring options to solve this by examining the source code for bash
  downloaded here: file:/home/kauffman/Downloads/bash-src/
- Notable is the ~notify_of_job_status()~ function which prints the
  error message according criteria here:
  file:/home/kauffman/Downloads/bash-src/jobs.c::4320
  1. Not interactive; have tried starting testy with ~bash -i~ but
     this leads to other problems
  2. Signal that killed the program is trapped by testy; this works
     out alright, don't generally expect that testy will generate
     these errors but need to check whether
     - trap a signal that needs to be sent to the program
     - signaled program should die on this
     - can't kill testy with signaling
Using the trap solution for now as after testing this with blather and
commando, it does not seem to have any major problems and does indeed
suppress the error messages I wanted silenced.

May need to revisit this as the child processes inherit the traps and
if they are bash processes, may change their behavior.

** DONE Multi Process testing

#+BEGIN_SRC text
> START server ./bl_server gotham
> SHELL kill -15 ${program_pid[server]}
> OUTPUT server
#+END_SRC

#+TESTY: program="TESTY_MULTI"

#+BEGIN_SRC text
> START server ./bl_server gotham
> START bruce ./bl_client gotham bruce
> START clark ./bl_client gotham clark
> INPUT bruce hey
> INPUT clark yo, what's up?
> INPUT bruce not much
> INPUT clark gotta go
> INPUT bruce me too
> INPUT bruce %EOF
> INPUT clark %EOF
> SIGNAL server -15 ${program_pid[server]}
> OUTPUT server
# server output goes here
> OUTPUT bruce
# bruce's output goes here
> OUTPUT clark
# clark's output goes here

# Not sure on this section what to do
> VALGRIND_CHECK server
> VALGRIND_CHECK bruce
> VALGRIND_CHECK clark
#+END_SRC

#+BEGIN_SRC sh
SHELL kill -15 %PNAME[server]

#+END_SRC
*** notes 
- the example above illustrates that this command set as it would
  exist in testy looks more like another interpreter of some type
- as I have started to experiment with coding it in bash, it feels
  more like a subprogram
- particularly the declarations about output would be nice for testy
  to have inline and then just check the output lines as if it was an
  interpreter
- this would create a dependency on another file thought which is a
  little undesirable

Tue 18 Aug 2020 09:50:13 AM CDT 
- Altered the syntax away from the above somewhat but the general
  scheme is still what I ended up using
- see the banter/ directory for an example 

